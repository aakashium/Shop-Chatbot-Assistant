{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import time \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Pinecone Configuration\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "spec = ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "index_name = \"shop-product-catalog\"\n",
    "\n",
    "# Connect to the index\n",
    "my_index=pc.Index(index_name)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d7a2fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11376\\638543296.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d16405fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index=my_index,\n",
    "    embedding=model,\n",
    "    text_key=\"Description\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73f57681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Gender': 'Women', 'Price': '10999', 'PrimaryColor': 'Purple', 'ProductBrand': 'Adidas', 'ProductName': 'Gazelle Pro 2'}, page_content='Retro-inspired running shoes with a sleek design and supportive upper')]\n"
     ]
    }
   ],
   "source": [
    "query=\"What is the price of Gazelle Adidas product?\"\n",
    "\n",
    "result= vectorstore.similarity_search(query, k=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e90bc027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai \n",
    "load_dotenv()\n",
    "\n",
    "chat_history=[]\n",
    "\n",
    "system_message=(\"\"\"\n",
    "    You are a helpful and respective shop assistant who answers queries relevant only to the products known to you.\n",
    "    Please answer all the questions as a professional and customer-friendly tone. If a query lacks a direct answer related to the product,\n",
    "    then generate a response based on related features. If a question is anything other than shopping, reply with, 'I can only provide answers related to the store only.' \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0caddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_answer(system_message, chat_history, prompt):\n",
    "    \"\"\"\n",
    "    Generate AI response using Gemini model with memory of chat history.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build conversation messages in proper chat format\n",
    "    chat = model.start_chat(history=[\n",
    "            {\"role\": \"user\", \"parts\": [system_message]},\n",
    "            *[\n",
    "                {\"role\": \"user\" if msg.startswith(\"User:\") else \"model\",\n",
    "                 \"parts\": [msg.split(\":\", 1)[1].strip()]}\n",
    "                for msg in chat_history\n",
    "            ]\n",
    "        ])\n",
    "        \n",
    "    # Generate response\n",
    "    response = chat.send_message(prompt)\n",
    "    answer = response.text.strip()\n",
    "\n",
    "    # Update chat history\n",
    "    chat_history.append(f\"User: {prompt}\")\n",
    "    chat_history.append(f\"Assistant: {answer}\")\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69f61d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_chunk(query, vectorestore):\n",
    "    results=vectorestore.similarity_search(query, k=1)\n",
    "    if results:\n",
    "        metadata=results[0].metadata\n",
    "        context=(\n",
    "            f'Product Name: {metadata.get(\"ProductName\",\"Not Available\")}\\n'\n",
    "            f'Brand: {metadata.get(\"Brand\",\"Not Available\")}\\n'\n",
    "            f'Price: {metadata.get(\"Price\",\"Not Available\")}\\n'\n",
    "            f'Color: {metadata.get(\"Color\",\"Not Available\")}\\n'\n",
    "            f'Description: {results[0].page_content}'\n",
    "            )\n",
    "        return context\n",
    "    return \"No relevant search\"\n",
    "\n",
    "def make_prompt(query,context):\n",
    "    return f\"Query: {query}\\n\\nContext:\\n{context}\\n\\nAnswer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Alright! We have the Gazelle Pro 2 available. The price is 10,999. Can I help you with anything else regarding these, like checking for available sizes or other details?\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    query=\"What is the price of Gazelle Adidas product?\"\n",
    "    relevant_text=get_relevant_chunk(query,vectorstore)\n",
    "    prompt=make_prompt(query, relevant_text)\n",
    "\n",
    "    answer=gen_answer(system_message,chat_history,prompt)\n",
    "    print(\"Answer:\",answer)\n",
    "\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550269b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Shop_Catalog_Chatbot (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
